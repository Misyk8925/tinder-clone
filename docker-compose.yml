services:

  localstack:
    image: localstack/localstack:latest
    ports:
      - "4566:4566"  # All AWS services
      - "4510-4559:4510-4559"  # External services
    environment:
      - SERVICES=s3  # Only enable what you need
      - DEBUG=1
      - DATA_DIR=/tmp/localstack/data
      - DOCKER_HOST=unix:///var/run/docker.sock
    volumes:
      - "./localstack-data:/tmp/localstack"
      - "/var/run/docker.sock:/var/run/docker.sock"

  postgres:
    image: postgres:16-alpine
    restart: unless-stopped
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: profiles
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - profiles-pgdata:/var/lib/postgresql/data


  redis:
    image: redis:8.2.1-alpine
    restart: "no"
    ports:
      - "6379:6379"
    healthcheck:
      test: redis-cli ping
      interval: 10s
      timeout: 5s
      start_period: 10s
      retries: 5

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    restart: unless-stopped
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    restart: unless-stopped
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    healthcheck:
      test: kafka-broker-api-versions --bootstrap-server localhost:9092
      interval: 10s
      timeout: 10s
      start_period: 30s
      retries: 5

    # NEW: Elasticsearch for storing logs
  elasticsearch:
      image: docker.elastic.co/elasticsearch/elasticsearch:8.12.0
      container_name: elasticsearch
      environment:
        - discovery.type=single-node
        - xpack.security.enabled=false
        - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      ports:
        - "9200:9200"
      volumes:
        - elasticsearch-data:/usr/share/elasticsearch/data
      healthcheck:
        test: [ "CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1" ]
        interval: 30s
        timeout: 10s
        retries: 5

    # NEW: Logstash for collecting logs
  logstash:
      image: docker.elastic.co/logstash/logstash:8.12.0
      container_name: logstash
      ports:
        - "5010:5000/tcp"
      environment:
        - "LS_JAVA_OPTS=-Xmx256m -Xms256m"
      depends_on:
        - elasticsearch
      command: |
        bash -c "
        cat > /usr/share/logstash/pipeline/logstash.conf <<EOF
        input {
          tcp {
            port => 5000
            codec => json
          }
        }
        output {
          elasticsearch {
            hosts => ['http://elasticsearch:9200']
            index => 'logstash-%{+YYYY.MM.dd}'
          }
          stdout { codec => rubydebug }
        }
        EOF
        /usr/local/bin/docker-entrypoint
        "

    # NEW: Kibana for viewing logs
  kibana:
      image: docker.elastic.co/kibana/kibana:8.12.0
      container_name: kibana
      ports:
        - "5601:5601"
      environment:
        - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      depends_on:
        - elasticsearch


networks:
  supabase_network_michael:
    external: true

volumes:
  profiles-pgdata:
  elasticsearch-data:
      driver: local